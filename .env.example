# Context Windows Laboratory - Environment Configuration
# Copy this file to .env and customize as needed

# ============================================================================
# EXPERIMENT CONFIGURATION
# ============================================================================

# Number of documents to generate per experiment
EXPERIMENT1_NUM_DOCS=15
EXPERIMENT1_WORDS_PER_DOC=200

EXPERIMENT2_DOC_COUNTS=2,5,10,20,50
EXPERIMENT2_WORDS_PER_DOC=200

EXPERIMENT3_NUM_DOCUMENTS=20
EXPERIMENT3_TOP_K=3

EXPERIMENT4_NUM_ACTIONS=10
EXPERIMENT4_MAX_TOKENS=2000

# ============================================================================
# OUTPUT CONFIGURATION
# ============================================================================

# Base directory for results
RESULTS_DIR=src/data/results

# Image output settings
IMAGE_DPI=300
IMAGE_FORMAT=png
IMAGE_WIDTH=10
IMAGE_HEIGHT=6

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log file path (leave empty to log to console only)
LOG_FILE=

# Log format
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# ============================================================================
# RANDOM SEED (for reproducibility)
# ============================================================================

# Set a seed for reproducible results (leave empty for random)
RANDOM_SEED=42

# ============================================================================
# TEXT GENERATION CONFIGURATION
# ============================================================================

# Critical fact for Experiment 1
CRITICAL_FACT=The CEO of the company is David Cohen

# Hebrew query for Experiment 3
HEBREW_QUERY=מה תופעות הלוואי של התרופה

# Topics for Hebrew documents (comma-separated)
HEBREW_TOPICS=technology,law,medicine

# ============================================================================
# METRICS CONFIGURATION
# ============================================================================

# Token estimation (characters per token)
CHARS_PER_TOKEN=4

# Cost per 1K tokens (USD)
COST_PER_1K_TOKENS=0.0001

# Accuracy threshold for fuzzy matching
ACCURACY_THRESHOLD=0.6

# ============================================================================
# LLM CONFIGURATION (for future real LLM integration)
# ============================================================================

# LLM Provider: ollama, openai, anthropic
LLM_PROVIDER=ollama

# Ollama settings
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# OpenAI settings (if using OpenAI)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-3.5-turbo

# Anthropic settings (if using Claude)
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# ============================================================================
# RAG CONFIGURATION (for future real RAG integration)
# ============================================================================

# Vector database
VECTOR_DB=chromadb
VECTOR_DB_PATH=src/data/vectordb

# Embedding model
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_DIMENSION=768

# Chunk settings
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# ============================================================================
# PERFORMANCE CONFIGURATION
# ============================================================================

# Enable parallel processing
ENABLE_PARALLEL=false

# Number of workers for parallel processing
NUM_WORKERS=4

# Cache results
ENABLE_CACHE=false
CACHE_DIR=src/data/cache

# ============================================================================
# VISUALIZATION CONFIGURATION
# ============================================================================

# Color scheme
COLOR_START=#2ecc71
COLOR_MIDDLE=#e74c3c
COLOR_END=#3498db

# Show plots automatically
AUTO_SHOW_PLOTS=true

# Save plots automatically
AUTO_SAVE_PLOTS=true

# ============================================================================
# EXPERIMENT MODES
# ============================================================================

# Use mock LLM (true) or real LLM (false)
USE_MOCK_LLM=true

# Run in test mode (reduced dataset sizes)
TEST_MODE=false

# Verbose output
VERBOSE=false
